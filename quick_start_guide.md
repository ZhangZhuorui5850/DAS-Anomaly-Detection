# DASå…‰çº¤æ„Ÿæµ‹ä»ªå¼‚å¸¸äº‹ä»¶ä¾¦æµ‹ç³»ç»Ÿ

## ğŸ“ é¡¹ç›®ç»“æ„
```
das_anomaly_detection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # æ”¾ç½®åŸå§‹CSVæ•°æ®
â”‚   â”œâ”€â”€ processed/        # é¢„å¤„ç†åçš„æ•°æ®
â”‚   â””â”€â”€ features/         # æå–çš„ç‰¹å¾
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ config.py          # âœ… é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ preprocessing.py   # âœ… æ•°æ®é¢„å¤„ç†
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ feature_extraction.py  # âœ… ç‰¹å¾æå–
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ classical/
â”‚       â”‚   â””â”€â”€ classical_models.py  # âœ… SVM/RF/XGBoost/GMM
â”‚       â””â”€â”€ deep_learning/
â”‚           â””â”€â”€ lstm_cnn.py    # âœ… LSTM-CNN/LSTM-AE/1D-CNN
â”œâ”€â”€ checkpoints/          # æ¨¡å‹ä¿å­˜
â”œâ”€â”€ logs/                 # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ results/              # ç»“æœè¾“å‡º
â”œâ”€â”€ main.py              # âœ… ä¸»ç¨‹åº
â””â”€â”€ requirements.txt      # ä¾èµ–åŒ…
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n das python=3.9
conda activate das

# å®‰è£…ä¾èµ–
pip install numpy pandas scipy scikit-learn xgboost
pip install torch torchvision  # æˆ–ä»å®˜ç½‘å®‰è£…é€‚åˆä½ CUDAç‰ˆæœ¬çš„PyTorch
pip install matplotlib seaborn tqdm pyyaml joblib
```

### 2. æ•°æ®å‡†å¤‡
```bash
# å°†ç¤ºä¾‹æ•°æ®.csvæ”¾å…¥data/raw/ç›®å½•
cp ç¤ºä¾‹æ•°æ®.csv data_preprocess/raw/
```

### 3. è¿è¡Œå®Œæ•´æµç¨‹
```bash
# æ–¹å¼1: ä¸€é”®è¿è¡Œ(åŒ…å«é¢„å¤„ç†ã€ç‰¹å¾æå–ã€è®­ç»ƒã€è¯„ä¼°)
python main.py --mode all

# æ–¹å¼2: åˆ†æ­¥è¿è¡Œ
python main.py --mode preprocess    # æ•°æ®é¢„å¤„ç†
python main.py --mode extract       # ç‰¹å¾æå–
python main.py --mode train --model all  # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
python main.py --mode eval          # æ¨¡å‹è¯„ä¼°
```

### 4. è®­ç»ƒç‰¹å®šæ¨¡å‹
```bash
# è®­ç»ƒXGBoost(æ¨è,é€Ÿåº¦å¿«)
python main.py --mode train --model xgboost

# è®­ç»ƒLSTM-CNN(æ•ˆæœæœ€å¥½)
python main.py --mode train --model lstm_cnn

# è®­ç»ƒæ‰€æœ‰ç»å…¸MLæ¨¡å‹
python main.py --mode train --model svm
python main.py --mode train --model random_forest
python main.py --mode train --model gmm
```

## ğŸ“Š é¢„æœŸæ€§èƒ½(åŸºäºæ–‡çŒ®)

| æ¨¡å‹ | F1-Score | TDR | FAR | è®­ç»ƒé€Ÿåº¦ |
|------|----------|-----|-----|---------|
| **LSTM-CNN** | **85-93%** | **â‰¥80%** | **â‰¤10%** | æ…¢ |
| XGBoost | 80-88% | 75-85% | 10-15% | å¿« |
| Random Forest | 75-85% | 70-80% | 15-20% | ä¸­ |
| SVM | 75-85% | 70-80% | 15-20% | ä¸­ |
| GMM | 70-80% | 65-75% | 20-25% | å¿« |

## ğŸ”§ å…³é”®é…ç½®ä¿®æ”¹

ç¼–è¾‘ `src/utils/config.py`:
```python
# æ•°æ®é…ç½®
RANDOM_SEED = 42
TRAIN_RATIO = 0.6
VAL_RATIO = 0.2

# å½’ä¸€åŒ–æ–¹æ³•(é‡è¦!)
NORMALIZATION_METHOD = 'high_freq_energy'  # åº”å¯¹è·ç¦»è¡°å‡

# æ—¶é—´çª—å£
WINDOW_SIZE = 5  # æ»‘åŠ¨çª—å£å¤§å°

# æ·±åº¦å­¦ä¹ è®­ç»ƒ
BATCH_SIZE = 32
NUM_EPOCHS = 100
LEARNING_RATE = 0.001
```

## ğŸ“ˆ æŸ¥çœ‹ç»“æœ
```bash
# ç»“æœä¿å­˜ä½ç½®
results/
â”œâ”€â”€ classical_results_YYYYMMDD_HHMMSS.csv
â”œâ”€â”€ deep_results_YYYYMMDD_HHMMSS.csv
â””â”€â”€ evaluation_results_YYYYMMDD_HHMMSS.csv

# æ¨¡å‹ä¿å­˜ä½ç½®
checkpoints/
â”œâ”€â”€ xgboost_YYYYMMDD_HHMMSS.pkl
â”œâ”€â”€ lstm_cnn_best_YYYYMMDD_HHMMSS.pth
â””â”€â”€ ...
```

## ğŸ¯ æ¨¡å—ä½¿ç”¨è¯´æ˜

### å•ç‹¬ä½¿ç”¨æ•°æ®é¢„å¤„ç†

```python
from src.utils.config import Config
from src.data_preprocess.preprocessing import DASDataLoader, DASPreprocessor

# åŠ è½½æ•°æ®
loader = DASDataLoader(Config.RAW_DATA_DIR / "ç¤ºä¾‹æ•°æ®.csv")
df = loader.load_data()

# é¢„å¤„ç†
preprocessor = DASPreprocessor(Config)
df_clean = preprocessor.preprocess_pipeline(df, fit=True)
```

### å•ç‹¬ä½¿ç”¨ç‰¹å¾æå–
```python
from src.features.feature_extraction import FeatureExtractor

extractor = FeatureExtractor(Config)
features = extractor.extract_features_batch(X_data)
```

### å•ç‹¬è®­ç»ƒæ¨¡å‹
```python
from src.models.classical.classical_models import create_classical_model

# è®­ç»ƒXGBoost
model = create_classical_model('xgboost', Config)
model.train(X_train, y_train, X_val, y_val)
model.save('checkpoints/my_model.pkl')
```

## ğŸ” å…³é”®æŠ€æœ¯è¦ç‚¹

### 1. æ•°æ®é¢„å¤„ç†
- **ç¼ºå¤±å€¼å¤„ç†**: ç©ºé—´æ’å€¼
- **å½’ä¸€åŒ–**: é«˜é¢‘èƒ½é‡å½’ä¸€åŒ–(åº”å¯¹è·ç¦»è¡°å‡)
- **å»å™ª**: é¢‘è°±å‡æ³•(å¯é€‰)

### 2. ç‰¹å¾å·¥ç¨‹
- **æ—¶åŸŸ**: èƒ½é‡ã€å³°å€¼ã€è¿‡é›¶ç‡ã€ååº¦ã€å³°åº¦
- **é¢‘åŸŸ**: 8ä¸ªé¢‘å¸¦èƒ½é‡ã€è°±è´¨å¿ƒã€è°±ç†µ
- **ç©ºé—´**: ç©ºé—´æ¢¯åº¦ã€èƒ½é‡è´¨å¿ƒã€å³°å€¼ä½ç½®

### 3. æ¨¡å‹é€‰æ‹©
- **ç»å…¸ML**: éœ€è¦æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹,å¯è§£é‡Šæ€§å¼º
- **æ·±åº¦å­¦ä¹ **: ç«¯åˆ°ç«¯å­¦ä¹ ,æ€§èƒ½æœ€ä¼˜

### 4. è¯„ä¼°æŒ‡æ ‡
- **ä¸»è¦**: F1-Score, TDR(çœŸå®æ£€æµ‹ç‡), FAR(è¯¯æŠ¥ç‡)
- **æ¬¡è¦**: å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€AUC-ROC

## âš ï¸ å¸¸è§é—®é¢˜

### 1. å†…å­˜ä¸è¶³
```python
# ä¿®æ”¹æ‰¹å¤§å°
Config.BATCH_SIZE = 16  # ä»32é™åˆ°16
```

### 2. CUDAé”™è¯¯
```python
# ä½¿ç”¨CPU
Config.DEVICE = torch.device('cpu')
```

### 3. æ•°æ®ä¸å¹³è¡¡
```python
# å·²åœ¨æ¨¡å‹ä¸­å¤„ç†(class_weight='balanced')
# XGBoostè‡ªåŠ¨è®¡ç®—scale_pos_weight
```

### 4. è®­ç»ƒå¤ªæ…¢
```python
# å…ˆç”¨XGBoostå¿«é€ŸéªŒè¯
python main.py --mode train --model xgboost

# å†ç”¨æ·±åº¦å­¦ä¹ ä¼˜åŒ–
python main.py --mode train --model lstm_cnn
```

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Xu et al. (2018)** - "Pattern recognition based on time-frequency analysis and CNNs for vibrational events in Ï†-OTDR"
   - è´¡çŒ®: CNN+é¢‘è°±å›¾æ–¹æ³•, å‡†ç¡®ç‡>90%

2. **Duraj et al. (2025)** - "Detection of Anomalies in Data Streams Using LSTM-CNN"
   - è´¡çŒ®: LSTM-CNNæ··åˆæ¶æ„, F1=88-93%

3. **Tejedor et al. (2016)** - "Towards Prevention of Pipeline Integrity Threats using Smart Fiber Optic"
   - è´¡çŒ®: é«˜é¢‘èƒ½é‡å½’ä¸€åŒ–, GMMåˆ†ç±»å™¨, çœŸå®ç®¡é“æ•°æ®

## ğŸ“§ è”ç³»æ–¹å¼

æœ‰é—®é¢˜è¯·æIssueæˆ–å‘é€é‚®ä»¶åˆ°: your_email@example.com

## ğŸ“„ License

MIT License